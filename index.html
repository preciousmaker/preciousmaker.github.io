<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>my precious - www.myprecious.com</title><meta name="author" content="田一顷"><meta name="copyright" content="田一顷"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="田一顷">
<meta property="og:type" content="website">
<meta property="og:title" content="my precious">
<meta property="og:url" content="https://github.com/preciousmaker/preciousmaker.github.io/index.html">
<meta property="og:site_name" content="my precious">
<meta property="og:description" content="田一顷">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/preciousmaker/preciousmaker.github.io/img/header.png">
<meta property="article:author" content="田一顷">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/preciousmaker/preciousmaker.github.io/img/header.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://github.com/preciousmaker/preciousmaker.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-08-11 18:36:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/header.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">58</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div></div><hr/></div></div><div id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(/img/top_img.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">my precious</a></span><span id="menus"><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site-title">my precious</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E5%9B%9B)%20Shuffle%E4%BC%98%E5%8C%96/" title="Spark - 性能优化(四) Shuffle优化">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(四) Shuffle优化"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E5%9B%9B)%20Shuffle%E4%BC%98%E5%8C%96/" title="Spark - 性能优化(四) Shuffle优化">Spark - 性能优化(四) Shuffle优化</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-08-11T10:22:07.873Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">大多数Spark作业的性能主要就是消耗在了shuffle环节，因为该环节包含了大量的磁盘IO、序列化、网络数据传输等操作。因此，如果要让作业的性能更上一层楼，就有必要对shuffle过程进行调优。但是也必须提醒大家的是，影响一个Spark作业性能的因素，主要还是代码开发、资源参数以及数据倾斜，shuffle调优只能在整个Spark的性能调优中++占到一小部分而已++。因此大家务必把握住调优的基本原则，千万不要舍本逐末。
ShuffleManager发展概述在Spark的源码中，负责shuffle过程的执行、计算和处理的组件主要就是ShuffleManager，也即shuffle管理器。而随着Spark的版本的发展，ShuffleManager也在不断迭代，变得越来越先进。在Spark 1.2以前，默认的shuffle计算引擎是HashShuffleManager。该ShuffleManager而HashShuffleManager有着一个非常严重的弊端，就是会产生大量的中间磁盘文件，进而由大量的磁盘IO操作影响了性能。因此在Spark 1.2以后的版本中，默认的ShuffleManag ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%89)%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" title="Spark - 性能优化(三) 数据倾斜">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(三) 数据倾斜"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%89)%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" title="Spark - 性能优化(三) 数据倾斜">Spark - 性能优化(三) 数据倾斜</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-08-11T10:22:07.869Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">数据倾斜发生时的现象
绝大多数task执行得都非常快，但个别task执行极慢。比如，总共有1000个task，997个task都在1分钟之内执行完了，但是剩余两三个task却要一两个小时。这种情况很常见。
原本能够正常执行的Spark作业，某天突然报出OOM（内存溢出）异常，检查后发现是代码问题。这种情况比较少见。

数据倾斜发生的原理数据倾斜的原理很简单：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。
因此出现数据倾斜的时候，Spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。
下图就是一个很清晰的例子：hello这个key，在三 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%BA%8C)%20%E8%B5%84%E6%BA%90%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(二) 资源参数调优">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(二) 资源参数调优"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%BA%8C)%20%E8%B5%84%E6%BA%90%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(二) 资源参数调优">Spark - 性能优化(二) 资源参数调优</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-08-11T10:22:07.865Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">资源参数调优概述Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。
Spark作业基本运行原理Spark作业基本运行原理
我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式(deploy-mode)不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。(client或者cluster)Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器(可以是Spark Standalone集群，也可以是其他的资源管理集群，使用的较多的是YARN作为资源管理集群)申请运行Spark作业需要使用的资源，这里的资源指的就是Exe ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%80)%20%E5%BC%80%E5%8F%91%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(一) 开发调优">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(一) 开发调优"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%80)%20%E5%BC%80%E5%8F%91%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(一) 开发调优">Spark - 性能优化(一) 开发调优</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-08-11T10:22:07.860Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">Spark性能优化的第一步，就是要在开发Spark作业的过程中注意和应用一些性能优化的基本原则。包括：RDD lineage(血统)设计、算子的合理使用、特殊操作的优化等。在开发过程中，时时刻刻都应该注意以上原则，并将这些原则根据具体的业务以及实际的应用场景，灵活地运用到自己的Spark作业中。
原则一 : 避免创建重复的RDD我们在开发过程中要注意：对于同一份数据，只应该创建一个RDD，不能创建多个RDD来代表同一份数据。
比如，针对同一个HDFS文件，执行了多次textFile方法，创建了多个RDD出来，然后分别对每个RDD都执行了一个算子操作，那么加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。
原则二 : 尽可能复用同一个RDD除了要避免在开发过程中对一份完全相同的数据创建多个RDD之外，在对不同的数据执行算子操作时还要尽可能地复用一个RDD。
比如，有一个RDD的数据格式是KV类型的，另一个是单value类型的，并且这两个RDD的value是完全一样的。那么我们就可以只使用KV类型的那个RDD，因为其中已经包含了另一个的数据。对于类似这种多个RDD的数据有重叠 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/07/27/Spark%20-%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F/" title="Spark - 自定义排序">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 自定义排序"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/27/Spark%20-%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F/" title="Spark - 自定义排序">Spark - 自定义排序</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-27T14:38:56.158Z" title="发表于 2021-07-27 22:38:56">2021-07-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">排序有很多种方法，这里暂且介绍几种自定义排序例如数据是
12val products = sc.parallelize(List(&quot;皮鞭 20 10&quot;,&quot;蜡烛 20 1000&quot;,&quot;扑克牌 5 2000&quot;,&quot;电视机 17999 1000&quot;),1)// 这里设置一个分区是避免foreach根据不同分区排序后依次输出，产生不必要的误会，就直接设施为一个分区
第一列是 name ，第二列是 price ，第三列是 amount
普通排序例如，按照 price 的升序，数量的 amount 降序排列
123456789101112val result = products.map(x =&gt; &#123;  val splits = x.split(&quot; &quot;)  val name = splits(0)  val price = splits(1).toDouble  val amount = splits(2).toInt  (name, price, amount)&#125;)result ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/07/22/Spark%20-%20SparkSQL%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E5%92%8C%E7%AE%97%E5%AD%90/" title="Spark - SparkSQL基础语法和算子">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - SparkSQL基础语法和算子"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/22/Spark%20-%20SparkSQL%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E5%92%8C%E7%AE%97%E5%AD%90/" title="Spark - SparkSQL基础语法和算子">Spark - SparkSQL基础语法和算子</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-22T11:11:08.287Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">spark-shell –jars *.jar这样有时候会报错 driver找不到对应的jar，可以再加一个参数 –driver-class-path *.jar
RDD转为DF/DS有两种方式
reflection(反射)要求这个RDD要有case class，其实就是定义了表的schema信息
123case class Person(name:String, age:Int)sc.textFile(file://).map(一些操作).map(x =&gt; Person(x(0),x(1))).toDF()

还可以df转成RDD : df.rdd
123df.rdd.map(x =&gt; x(0)).collect()// 或者df.map(x =&gt; x.getAs[String](&quot;name&quot;)).show()

编程的时候指定SchemaCreate an RDD of Rows from the original RDD;从原始RDD创建一个Row类型的RDD
12val data: RDD[Row] = sc.textFile().map( ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/07/22/Spark%20-%20%E5%88%9D%E8%AF%86Spark%20SQL%E5%8F%8A%E5%85%B6%E7%BC%96%E7%A8%8B/" title="Spark - 初识Spark SQL及其编程">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 初识Spark SQL及其编程"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/22/Spark%20-%20%E5%88%9D%E8%AF%86Spark%20SQL%E5%8F%8A%E5%85%B6%E7%BC%96%E7%A8%8B/" title="Spark - 初识Spark SQL及其编程">Spark - 初识Spark SQL及其编程</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-22T11:11:08.284Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">Spark SQL官方文档基调：Spark SQL is Apache Spark’s module for working with structured data.Spark SQL是Apache Spark用于处理结构化数据的模块。
Spark SQL在maven工程里，是Spark项目的一个子模块
Integrated 集成Seamlessly mix SQL queries with Spark programs.将 SQL 查询与 Spark 程序无缝结合。
spark-shell启动的时候，会创建 spark context(sc) spark session(spark)
Uniform Data Access统一数据访问
Connect to any data source the same way.以相同的方式连接到任何数据源。
这个是 Spark SQL 最重要的一点，多数据源访问，在数据平台中是一个非常常见的功能使用Spark引擎，可以对接不同数据源的数据，然后做相应的一些操作一个框架最终能否落地到SQL，这是我们选型的一个重要参考指标
Hive Integra ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/07/22/Spark%20-%20External%20DataSource%20API/" title="Spark - External DataSource API">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - External DataSource API"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/22/Spark%20-%20External%20DataSource%20API/" title="Spark - External DataSource API">Spark - External DataSource API</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-22T11:11:08.282Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">超级重要有内置(build-in),还有自研的
基本都需要导这个包 import org.apache.spark.sql._
LOAD SAVELOAD12345val df1 = spark.read.format(&quot;text&quot;).load(&quot;path&quot;) //读进来的字段名叫做value//可以简写为val df1 = spark.read.text(&quot;path&quot;) //其实底层调用的还是.format(&quot;text&quot;).load(&quot;path&quot;)val ds1 = spark.read.textFile(&quot;path&quot;) //注意这个返回值是DS

SAVE12df1.write.format(&quot;text&quot;).save(&quot;path&quot;) //注意这个path不能提前存在，因为SaveMode默认是errorifexistsdf1.write.format(&quot;text&quot;).mode(SaveMode.Appen ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/07/22/Spark%20-%20Monitoring(%E7%9B%91%E6%8E%A7)/" title="Spark - Monitoring(监控)">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - Monitoring(监控)"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/22/Spark%20-%20Monitoring(%E7%9B%91%E6%8E%A7)/" title="Spark - Monitoring(监控)">Spark - Monitoring(监控)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-22T11:11:08.279Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">官网
WebUI 默认4040，如果同时启动多个，那么查到4040被占用就会+1，使用4041端口，以此类推
这些信息只有在 application 运行期间可以访问到，sc.stop 之后网页就就访问不到其实这些信息是以 json 形式存在 eventlog 中的，WebUI只是解析展示
如果想要运行结束后去看这些信息，可以在启动 application 之前将 spark.eventlog.enabled 设置为true
作用1.A list of scheduler stages and tasksstage和task列表
2.A summary of RDD sizes and memory usageRDD 大小和内存使用的总结(cache)
3.Environmental information环境信息
4.Information about the running executors有关正在运行的执行程序的信息
./sbin/start-history-server.sh启动一个进程，创建一个WebUI 默认18080，用来展示未完成和已完成的 application
相 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/07/22/Spark%20-%20Spark%20on%20YARN%E8%AF%A6%E8%A7%A3/" title="Spark - Spark on YARN详解">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - Spark on YARN详解"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/22/Spark%20-%20Spark%20on%20YARN%E8%AF%A6%E8%A7%A3/" title="Spark - Spark on YARN详解">Spark - Spark on YARN详解</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-22T11:11:08.276Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">Spark on YARNhttps://www.cnblogs.com/bigdata1024/p/12116621.html
其实不仅仅是Spark，MR Flink HBase等都可以跑在YARN上关键就在于Application Master(AM)
–master yarn启动后产生四个进程YarnCoarseGrainedExecutorBackedYarnCoarseGrainedExecutorBackedExecutorLauncherSparkSubmit
YARN有重试机制，具体参数如下spark.yarn.maxAppAttempts yarn.resourcemanager.am.max-attempts in YARN  默认重试2次
Client模式
–deploy-mode client 默认就是client，也可以设置为 clusterAM：负责申请资源Driver：与AM通信，负责调度
因为Driver运行在本地，jars、作业的jar包、spark_conf内的东西，打成三个包，上传到HDFS，运行日志到这部分会卡顿
Cluster模式
如果是在c ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/header.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">田一顷</div><div class="author-info__description">田一顷</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">58</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div><a class="button--animated" id="card-info-btn" href="https://github.com/preciousmaker/preciousmaker.github.io"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E5%9B%9B)%20Shuffle%E4%BC%98%E5%8C%96/" title="Spark - 性能优化(四) Shuffle优化"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(四) Shuffle优化"/></a><div class="content"><a class="title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E5%9B%9B)%20Shuffle%E4%BC%98%E5%8C%96/" title="Spark - 性能优化(四) Shuffle优化">Spark - 性能优化(四) Shuffle优化</a><time datetime="2021-08-11T10:22:07.873Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%89)%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" title="Spark - 性能优化(三) 数据倾斜"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(三) 数据倾斜"/></a><div class="content"><a class="title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%89)%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/" title="Spark - 性能优化(三) 数据倾斜">Spark - 性能优化(三) 数据倾斜</a><time datetime="2021-08-11T10:22:07.869Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%BA%8C)%20%E8%B5%84%E6%BA%90%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(二) 资源参数调优"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(二) 资源参数调优"/></a><div class="content"><a class="title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%BA%8C)%20%E8%B5%84%E6%BA%90%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(二) 资源参数调优">Spark - 性能优化(二) 资源参数调优</a><time datetime="2021-08-11T10:22:07.865Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%80)%20%E5%BC%80%E5%8F%91%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(一) 开发调优"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 性能优化(一) 开发调优"/></a><div class="content"><a class="title" href="/2021/08/11/Spark%20-%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(%E4%B8%80)%20%E5%BC%80%E5%8F%91%E8%B0%83%E4%BC%98/" title="Spark - 性能优化(一) 开发调优">Spark - 性能优化(一) 开发调优</a><time datetime="2021-08-11T10:22:07.860Z" title="发表于 2021-08-11 18:22:07">2021-08-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/27/Spark%20-%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F/" title="Spark - 自定义排序"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 自定义排序"/></a><div class="content"><a class="title" href="/2021/07/27/Spark%20-%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F/" title="Spark - 自定义排序">Spark - 自定义排序</a><time datetime="2021-07-27T14:38:56.158Z" title="发表于 2021-07-27 22:38:56">2021-07-27</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>分类</span></div><ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/HDFS/"><span class="card-category-list-name">HDFS</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hive/"><span class="card-category-list-name">Hive</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LeetCode/"><span class="card-category-list-name">LeetCode</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Linux/"><span class="card-category-list-name">Linux</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/MapReduce/"><span class="card-category-list-name">MapReduce</span><span class="card-category-list-count">9</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/MySQL/"><span class="card-category-list-name">MySQL</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python/"><span class="card-category-list-name">Python</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Scala/"><span class="card-category-list-name">Scala</span><span class="card-category-list-count">3</span></a></li>
            <li class="card-category-list-item more is-center"><a class="card-category-list-link-more" href="/categories/">
                <span>查看更多</span><i class="fas fa-angle-right"></i></a></li>
            </ul></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">八月 2021</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">五月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/04/"><span class="card-archive-list-date">四月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">10</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/02/"><span class="card-archive-list-date">二月 2021</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/01/"><span class="card-archive-list-date">一月 2021</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><span class="card-archive-list-count">12</span></a></li><li class="card-archive-list-item more is-center"><a class="card-archive-list-link-more" href="/archives/">
              <span>查看更多</span><i class="fas fa-angle-right"  ></i></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">58</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-08-11T10:36:47.520Z"></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 田一顷</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>