<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>my precious - www.myprecious.com</title><meta name="author" content="田一顷"><meta name="copyright" content="田一顷"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="田一顷">
<meta property="og:type" content="website">
<meta property="og:title" content="my precious">
<meta property="og:url" content="https://github.com/preciousmaker/preciousmaker.github.io/page/2/index.html">
<meta property="og:site_name" content="my precious">
<meta property="og:description" content="田一顷">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/preciousmaker/preciousmaker.github.io/img/header.png">
<meta property="article:author" content="田一顷">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/preciousmaker/preciousmaker.github.io/img/header.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://github.com/preciousmaker/preciousmaker.github.io/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-07-28 00:49:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/header.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">54</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div></div><hr/></div></div><div id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(/img/top_img.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">my precious</a></span><span id="menus"><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site-title">my precious</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/07/20/Spark%20-%20RDD%E4%B8%AD%E7%9A%84transformation%E6%93%8D%E4%BD%9C(%E4%BA%8C)%20-%20%E5%9F%BA%E4%BA%8EKV%E7%B1%BB%E5%9E%8B/" title="Spark - RDD中的transformation操作(二) - 基于KV类型">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - RDD中的transformation操作(二) - 基于KV类型"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/20/Spark%20-%20RDD%E4%B8%AD%E7%9A%84transformation%E6%93%8D%E4%BD%9C(%E4%BA%8C)%20-%20%E5%9F%BA%E4%BA%8EKV%E7%B1%BB%E5%9E%8B/" title="Spark - RDD中的transformation操作(二) - 基于KV类型">Spark - RDD中的transformation操作(二) - 基于KV类型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-20T13:12:51.239Z" title="发表于 2021-07-20 21:12:51">2021-07-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">基于KV类型的transformation操作RDD编程场景可能不多，但是面试会问关于资源问题，大公司充足，能用硬件解决的就用硬件解决，调优的力度小中小型公司不够，只能去调优，先看partition，再看task
mapValuesPass each value in the key-value pair RDD through a map function without changing the keys;this also retains the original RDD’s partitioning.在不更改key的情况下，通过映射函数传递键值对RDD中的每个value；这也保留了原始RDD的分区。
1234567def mapValues[U](f: V =&gt; U): RDD[(K, U)] = self.withScope &#123;  val cleanF = self.context.clean(f)  new MapPartitionsRDD[(K, U), (K, V)](self,    (context, pid, iter) =&gt; iter.ma ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/07/20/Spark%20-%20RDD%E4%B8%AD%E7%9A%84transformation%E6%93%8D%E4%BD%9C(%E4%B8%80)/" title="Spark - RDD中的transformation操作(一)">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - RDD中的transformation操作(一)"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/20/Spark%20-%20RDD%E4%B8%AD%E7%9A%84transformation%E6%93%8D%E4%BD%9C(%E4%B8%80)/" title="Spark - RDD中的transformation操作(一)">Spark - RDD中的transformation操作(一)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-20T12:56:36.884Z" title="发表于 2021-07-20 20:56:36">2021-07-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">RDD两大核心操作transformation(转换)，action(行动)transformation是惰性的，不会真正运行，仅仅是记录了RDD之间的transformation，遇到action，这个job才会运行。
transformationmakeRDDsc.makeRDD(Seq,n) 可以将Seq转为RDD，第二个参数n可以控制分区数，不写就使用默认的分区数，例如setMaster(“local[4]”)，分区数就是默认就是4
textFile可以读取很多系统的数据，不限于本地和HDFS，包括AWS S3，URI都可以读，只要有包支持。压缩后的也可以，正则匹配也适用(*.log)
mapReturn a new RDD by applying a function to all elements of this RDD.通过将函数应用于此RDD的所有元素来返回新的RDD。对RDD中的元素都作用一个函数(一一映射)，并返回一个新RDD，不会修改分区数。
1234def map[U: ClassTag](f: T =&gt; U): RDD[U] = withScope &# ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/07/20/Spark%20-%20WC%E5%92%8CRDD%E4%BA%94%E5%A4%A7%E5%B1%9E%E6%80%A7/" title="Spark - WC和RDD五大属性">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - WC和RDD五大属性"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/20/Spark%20-%20WC%E5%92%8CRDD%E4%BA%94%E5%A4%A7%E5%B1%9E%E6%80%A7/" title="Spark - WC和RDD五大属性">Spark - WC和RDD五大属性</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-20T12:41:18.779Z" title="发表于 2021-07-20 20:41:18">2021-07-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">分析WC就像每学一门新的语言，第一步都是Hello World，对于数据方面，第一步总是写WC
WordCount12345678910111213141516171819202122232425object WC_App &#123;  def main(args: Array[String]): Unit = &#123;    System.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;hadoop&quot;)    val conf: SparkConf = new SparkConf().setAppName(&quot;WCApp&quot;).setMaster(&quot;local&quot;)    val sc: SparkContext = new SparkContext(conf)    //读本地文件没问题    //val rdd1: RDD[(String, Int)] = sc.textFile(&quot;data/wc/wc.txt&quot;).flatMap(_.split(&quot; & ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/07/20/Spark%20-%20%E5%88%9D%E8%AF%86Spark/" title="Spark - 初识Spark">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 初识Spark"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/07/20/Spark%20-%20%E5%88%9D%E8%AF%86Spark/" title="Spark - 初识Spark">Spark - 初识Spark</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-07-20T12:41:04.900Z" title="发表于 2021-07-20 20:41:04">2021-07-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">官网作者 : Matei Zaharia(马铁)官网 : http://spark.apache.org/
MapReduce VS SparkMapReduceMR适合处理离线批处理分为两部分 map + reduce，其中大多数情况下两者都有，但也有例外
有map无reduce如果是map之后直接输出则不需要reduce，例如where等场景
有reduce无map目前只知道一种场景是没有map有reduce，那就是hive中的GenericMRhttps://mp.weixin.qq.com/s/SkjHeuosdX-SzEC6AxGgGA但是看完感觉是hive自己做了一个map，可以看出hive还是有野心的
MR为什么比较慢？一般情况，map的中间结果写入磁盘，reduce的结果落地在HDFS如果一个作业由多个MR作业构成，第一个MR的输出是第二个MR的输入A =&gt; B =&gt; C =&gt; D每个作业之间都要落地，会涉及磁盘IO，网络IO，序列化等开销而且，无论MapTask还是ReduceTask都是进程级别，jps命令可以看到YarnChild等进程，JVM的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/05/11/Hive%20-%20%E5%85%83%E6%95%B0%E6%8D%AE/" title="Hive - 元数据">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hive - 元数据"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/05/11/Hive%20-%20%E5%85%83%E6%95%B0%E6%8D%AE/" title="Hive - 元数据">Hive - 元数据</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-05-11T12:18:41.393Z" title="发表于 2021-05-11 20:18:41">2021-05-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Hive/">Hive</a></span></div><div class="content">Hive的元数据一般存储在Mysql中Mysql版本：5.7.14Hive版本：1.1.0-cdh5.16.2一共62张表，简介一些比较重要的表
1234select count(*) from information_schema.TABLESwhere TABLE_SCHEMA = &#x27;your_database_name&#x27;;--结果为62

version 表
此表存着Hive的版本信息，有且只有一条数据。如果尝试删除此条信息和新增一条信息，都会导致Hive不可用。
与数据库有关的表dbs
dbs表存储Hive中数据库的信息，其中default为自带数据库，HDFS路径为 hdfs://precious:9000/user/hive/warehouse其他数据库为hadoop用户创建的，HDFS路径均为 warehouse下对应名字.db
database_params
database_params表存储数据库的相关参数，这些参数需要在创建库的时候加上WITH DBPROPERTIES (property_name=property_value, …)，我这里 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/04/10/ZK%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/" title="ZK选举机制">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ZK选举机制"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/04/10/ZK%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/" title="ZK选举机制">ZK选举机制</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-04-10T07:22:08.144Z" title="发表于 2021-04-10 15:22:08">2021-04-10</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/ZooKeeper/">ZooKeeper</a></span></div><div class="content">简介ZooKeeper是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。核心：文件系统 + 通知机制
为什么需要选举？选举出一个Leader，主要是为了保持分布式数据的一致性，每个节点的存储的数据保持同步。
三种服务器角色通常在分布式系统中，构成一个集群的每一台机器都有自己的角色，最典型的集群模式就是Master / Salve(主备模式)；但是在ZooKeeper中，引入了Leader、Follower、Observer三种角色。
LeaderLeader服务器是ZK集群工作的核心，是整个集群的管理者；Leader服务器为客户端提供读写服务，它是事务请求的唯一调度和处理者，保证集群事务处理的顺序性；同时也是集群内个服务器的调度者。
FollowerFollower是集群的跟随者，处理客户端非事务性请求(读取数据)；转发事务请求给Leader服务器；参与事务请求Proposal的投票；参与Leader选举投票。
Observer观察ZK集群的最新状态变化并将这些状态同步过来；对于非事务性请求可以进行独立处理；对于事务性请求，将会转发给Le ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/03/14/Spark%20-%20%E5%AE%89%E8%A3%85/" title="Spark - 安装">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 安装"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/03/14/Spark%20-%20%E5%AE%89%E8%A3%85/" title="Spark - 安装">Spark - 安装</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-03-14T13:19:47.344Z" title="发表于 2021-03-14 21:19:47">2021-03-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">安装下载地址由于服务器的hadoop版本是 hadoop-2.6.0-cdh5.16.2所以需要用到spark2.xhttps://www.apache.org/dyn/closer.lua/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz
安装上传至服务器，解压，软连接，环境变量
解压1$ tar -zxvf spark-3.1.1-bin-hadoop2.7.tgz -C ../app/

软连接1$ ln -s spark-3.1.1-bin-hadoop2.7/ spark

环境变量123456$ vi .bashrcexport SPARK_HOME=/home/hadoop/app/sparkexport PATH=$&#123;SPARK_HOME&#125;/bin:$PATH$ source .bashrc

验证12$ cd /home/hadoop/app/spark/bin$ spark-shell


出现这个表示成功
</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/03/11/Hive%20-%20UDF/" title="Hive - UDF">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hive - UDF"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/03/11/Hive%20-%20UDF/" title="Hive - UDF">Hive - UDF</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-03-11T15:02:39.961Z" title="发表于 2021-03-11 23:02:39">2021-03-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Hive/">Hive</a></span></div><div class="content">简介User Defind Function(UDF) 分为三大类：

   普通UDF函数，一进一出，例如upper
   UDAF，其中A表示 aggregation(聚合)，多进一出，例如count，max，min，sum等
   UDTF，其中T表示 Table，一进多出，例如lateral view explode

实现say_hello(temporary)实现一个sayHello的功能
pom.xml添加hive的依赖
12345&lt;dependency&gt;  &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;  &lt;artifactId&gt;hive-exec&lt;/artifactId&gt;  &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt;&lt;/dependency&gt;
按照个人hadoop的版本选择hive的版本
UDFHello.java需要继承UDF，根据UDF.java的源码可以看到这句话
1Implement one or  ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/03/11/Hive%20-%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/" title="Hive - 源码编译">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hive - 源码编译"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/03/11/Hive%20-%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/" title="Hive - 源码编译">Hive - 源码编译</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-03-11T10:56:17.733Z" title="发表于 2021-03-11 18:56:17">2021-03-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/Hive/">Hive</a></span></div><div class="content">名词解释在进行编译之前需要了解几个概念编译、maven
感谢吴老师的名词解释，在此提醒自己，要乐于分享。
编译.java/.scala ==&gt; .class ==&gt; .jar
编译就是将.java或.scala文件转成.class文件(字节码形式)，一般情况下，一个Java文件就对应了一个.class文件。很多.class文件会压缩成.jar文件，也就是常说的jar包。JVM运行的是.class文件。
在IDEA工具里，运行程序的时候，其实也有个编译过程，最终的.class文件都进了项目根目录的/target目录下。
Hive架构就是使用Java编写的，所以下载了Hive的源码之后，需要编译才可以使用。
maven开发中有个思想：避免重复造轮子也就是说我们需要学会借鉴其他人的代码，将好的代码，一般是jar包，添加到自己的项目目录下，代码中import一下，就可以调用其中的方法了。但这样也是有问题的，我们依赖的jar包越多，项目越臃肿，团队之间的协作也越困难。
如果有一个公共的jar包资源仓库就好了mave就是做这个事的，将远程资源仓库的jar包下载到本地仓库，供项目使用
除 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/03/08/MapReduce%E7%BC%96%E7%A8%8B%20-%20%E7%B1%BBSQL%E6%93%8D%E4%BD%9C/" title="MapReduce编程 - 类SQL操作">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MapReduce编程 - 类SQL操作"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/03/08/MapReduce%E7%BC%96%E7%A8%8B%20-%20%E7%B1%BBSQL%E6%93%8D%E4%BD%9C/" title="MapReduce编程 - 类SQL操作">MapReduce编程 - 类SQL操作</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-03-08T04:39:16.257Z" title="发表于 2021-03-08 12:39:16">2021-03-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/MapReduce/">MapReduce</a></span></div><div class="content">order by全局排序
sort by分区排序，分区内部有序
count() … group by例如
1SELECT COUNT(name) FROM emp GROUP BY name;
按name分组，求name出现的次数其实就是name这一列的词频统计
distinct其实就是 group byMapper和Reducer中，都是只关注key，也就是split后的word
123456789101112131415161718192021public static class MyMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt;&#123;	@Override    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;		final String line = value.toString().toLowerCase() ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/header.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">田一顷</div><div class="author-info__description">田一顷</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">54</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div><a class="button--animated" id="card-info-btn" href="https://github.com/preciousmaker/preciousmaker.github.io"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/07/27/Spark%20-%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F/" title="Spark - 自定义排序"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 自定义排序"/></a><div class="content"><a class="title" href="/2021/07/27/Spark%20-%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F/" title="Spark - 自定义排序">Spark - 自定义排序</a><time datetime="2021-07-27T14:38:56.158Z" title="发表于 2021-07-27 22:38:56">2021-07-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/22/Spark%20-%20SparkSQL%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E5%92%8C%E7%AE%97%E5%AD%90/" title="Spark - SparkSQL基础语法和算子"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - SparkSQL基础语法和算子"/></a><div class="content"><a class="title" href="/2021/07/22/Spark%20-%20SparkSQL%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E5%92%8C%E7%AE%97%E5%AD%90/" title="Spark - SparkSQL基础语法和算子">Spark - SparkSQL基础语法和算子</a><time datetime="2021-07-22T11:11:08.287Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/22/Spark%20-%20%E5%88%9D%E8%AF%86Spark%20SQL%E5%8F%8A%E5%85%B6%E7%BC%96%E7%A8%8B/" title="Spark - 初识Spark SQL及其编程"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - 初识Spark SQL及其编程"/></a><div class="content"><a class="title" href="/2021/07/22/Spark%20-%20%E5%88%9D%E8%AF%86Spark%20SQL%E5%8F%8A%E5%85%B6%E7%BC%96%E7%A8%8B/" title="Spark - 初识Spark SQL及其编程">Spark - 初识Spark SQL及其编程</a><time datetime="2021-07-22T11:11:08.284Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/22/Spark%20-%20External%20DataSource%20API/" title="Spark - External DataSource API"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - External DataSource API"/></a><div class="content"><a class="title" href="/2021/07/22/Spark%20-%20External%20DataSource%20API/" title="Spark - External DataSource API">Spark - External DataSource API</a><time datetime="2021-07-22T11:11:08.282Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/22/Spark%20-%20Monitoring(%E7%9B%91%E6%8E%A7)/" title="Spark - Monitoring(监控)"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark - Monitoring(监控)"/></a><div class="content"><a class="title" href="/2021/07/22/Spark%20-%20Monitoring(%E7%9B%91%E6%8E%A7)/" title="Spark - Monitoring(监控)">Spark - Monitoring(监控)</a><time datetime="2021-07-22T11:11:08.279Z" title="发表于 2021-07-22 19:11:08">2021-07-22</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>分类</span></div><ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/HDFS/"><span class="card-category-list-name">HDFS</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hive/"><span class="card-category-list-name">Hive</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LeetCode/"><span class="card-category-list-name">LeetCode</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Linux/"><span class="card-category-list-name">Linux</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/MapReduce/"><span class="card-category-list-name">MapReduce</span><span class="card-category-list-count">9</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/MySQL/"><span class="card-category-list-name">MySQL</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python/"><span class="card-category-list-name">Python</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Scala/"><span class="card-category-list-name">Scala</span><span class="card-category-list-count">3</span></a></li>
            <li class="card-category-list-item more is-center"><a class="card-category-list-link-more" href="/categories/">
                <span>查看更多</span><i class="fas fa-angle-right"></i></a></li>
            </ul></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">五月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/04/"><span class="card-archive-list-date">四月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">10</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/02/"><span class="card-archive-list-date">二月 2021</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/01/"><span class="card-archive-list-date">一月 2021</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><span class="card-archive-list-count">12</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/11/"><span class="card-archive-list-date">十一月 2020</span><span class="card-archive-list-count">6</span></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">54</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-07-27T16:49:40.276Z"></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 田一顷</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>